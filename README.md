# Pipeline de ML para Clasificaci√≥n de Patrones de I/O

Sistema de aprendizaje autom√°tico para clasificar patrones de acceso a disco (secuencial, aleatorio, mixto) y optimizar el readahead en el kernel Linux mediante KML (Kernel Machine Learning).

---

## üìã Contexto General del Proyecto

Este proyecto desarrolla un componente de red neuronal que clasifica patrones de I/O en tiempo real dentro del kernel Linux. El objetivo es predecir el tipo de patr√≥n de acceso (sequential, random, mixed) para ajustar din√°micamente el valor de readahead y mejorar el rendimiento del sistema de archivos.

### Flujo General del Proyecto

```
1. Dataset consolidado (CSV con caracter√≠sticas pre-calculadas)
   ‚Üì
2. Procesamiento y normalizaci√≥n de datos
   ‚Üì
3. Entrenamiento de red neuronal ligera
   ‚Üì
4. Exportaci√≥n a formato TorchScript
   ‚Üì
5. Integraci√≥n en kernel Linux mediante KML
   ‚Üì
6. Inferencia en tiempo real para ajustar readahead
```

**Tu responsabilidad**: Pasos 1-4 (desarrollo del modelo ML)  
**Compa√±ero**: Pasos 5-6 (integraci√≥n en kernel)

---

## üèóÔ∏è Estructura del C√≥digo

### Archivos Principales

#### `build_dataset_from_consolidated.py`
**¬øQu√© hace?**  
Procesa el dataset consolidado (`consolidated_dataset.csv`) y prepara los datos para entrenamiento.

**Funcionamiento:**
1. Lee el CSV con caracter√≠sticas ya calculadas por ventana
2. Mapea las columnas del CSV a las 5 caracter√≠sticas que necesita el modelo:
   - `trace_avg_sector_distance * 512` ‚Üí Distancia promedio (bytes)
   - `trace_sector_jump_ratio` ‚Üí Variabilidad
   - `bw_mean_kbps / iops_mean` ‚Üí Tama√±o promedio I/O (bytes)
   - `1 - trace_sector_jump_ratio` ‚Üí Ratio secuencial
   - `iops_mean` ‚Üí Tasa de I/O (IOPS)
3. Mapea etiquetas de texto (`sequential`, `random`, `mixed`) a n√∫meros (0, 1, 2)
4. Divide los datos en train/test (80/20) de forma estratificada
5. Normaliza las caracter√≠sticas usando `StandardScaler`
6. Guarda:
   - `data/processed/train.npz` y `test.npz` (datos normalizados)
   - `artifacts/scaler.pkl` (normalizador - **CR√çTICO para kernel**)
   - `artifacts/metadata.json` (metadatos del dataset)

**Por qu√© estas 5 caracter√≠sticas?**  
Capturan los aspectos distintivos de cada patr√≥n de forma eficiente y son computacionalmente baratas de calcular en tiempo real dentro del kernel.

#### `neuronal_red.py`
**¬øQu√© hace?**  
Define la arquitectura de la red neuronal.

**Arquitectura:**
```python
Input (5 caracter√≠sticas) 
  ‚Üí Capa Densa 1: 5 ‚Üí 32 neuronas + ReLU + Dropout(20%)
  ‚Üí Capa Densa 2: 32 ‚Üí 16 neuronas + ReLU
  ‚Üí Capa Densa 3: 16 ‚Üí 3 neuronas (logits)
  ‚Üí Salida: [score_sequential, score_random, score_mixed]
```

**¬øPor qu√© es "ligera"?**
- Solo 3 capas densas (no es una red profunda)
- M√°ximo 32 neuronas por capa
- Tama√±o total: ~15 KB
- Inferencia r√°pida (microsegundos)
- Optimizada para ejecuci√≥n en kernel donde los recursos son limitados

**Componentes:**
- `ReLU`: Funci√≥n de activaci√≥n que introduce no-linealidad
- `Dropout(0.2)`: Regularizaci√≥n que previene sobreajuste (desactiva 20% de neuronas aleatoriamente durante entrenamiento)
- `CrossEntropyLoss`: Funci√≥n de p√©rdida para clasificaci√≥n multi-clase

#### `train.py`
**¬øQu√© hace?**  
Entrena la red neuronal y exporta el modelo en formatos compatibles con el kernel.

**Proceso de entrenamiento:**
1. Carga los datos de entrenamiento y prueba
2. Crea un `DataLoader` con batches de 128 muestras
3. Inicializa el modelo, optimizador (Adam) y funci√≥n de p√©rdida
4. Entrena durante hasta 60 √©pocas con:
   - **Early stopping**: Se detiene si no mejora en 8 √©pocas consecutivas
   - **Validaci√≥n**: Eval√∫a en el conjunto de prueba cada √©poca
   - **Mejor modelo**: Guarda el modelo con mejor accuracy en validaci√≥n
5. Exporta el modelo en dos formatos:
   - `model.pth`: Pesos PyTorch (para Python)
   - `model_ts.pt`: **TorchScript** (para C/C++ y kernel) ‚≠ê **PRINCIPAL**
   - `model.onnx`: ONNX (opcional, si se requiere)

**Par√°metros de entrenamiento:**
- Learning rate: 0.001
- Batch size: 128
- Optimizador: Adam
- Early stopping: Paciencia de 8 √©pocas

#### `evaluate.py`
**¬øQu√© hace?**  
Eval√∫a el modelo entrenado y genera m√©tricas de rendimiento.

**M√©tricas generadas:**
- Accuracy general
- Matriz de confusi√≥n (muestra errores por clase)
- Guarda resultados en `artifacts/eval_summary.json`

---

## üöÄ C√≥mo Ejecutar el Pipeline Completo

### 1. Instalaci√≥n de Dependencias

```bash
pip install -r requirements.txt
```

**Dependencias principales:**
- `torch`: Framework de deep learning
- `numpy`, `pandas`: Manipulaci√≥n de datos
- `scikit-learn`: Normalizaci√≥n y divisi√≥n de datos
- `joblib`: Guardar/cargar el normalizador

### 2. Preparar el Dataset

**Requisitos del CSV:**
- Archivo: `consolidated_dataset.csv` en el directorio ra√≠z
- Debe tener una columna `label` con valores: `sequential`, `random`, `mixed`
- Debe contener las columnas necesarias para calcular las 5 caracter√≠sticas

**Ejecutar:**
```bash
python build_dataset_from_consolidated.py
```

**Salida esperada:**
```
Dataset procesado exitosamente!
  - Train: 691 muestras
  - Test: 173 muestras
  - Features: 5
  - Clases: 3
```

**Archivos generados:**
- `data/processed/train.npz` - Datos de entrenamiento normalizados
- `data/processed/test.npz` - Datos de prueba normalizados
- `artifacts/scaler.pkl` - Normalizador (necesario para kernel)
- `artifacts/metadata.json` - Metadatos del dataset

### 3. Entrenar el Modelo

```bash
python train.py
```

**Salida esperada:**
```
Epoch 001 | loss=1.0957 | val_acc=0.3353
Epoch 002 | loss=1.0646 | val_acc=0.3353
...
Epoch 031 | loss=0.1378 | val_acc=0.9711
Early stopping por paciencia.
Entrenamiento completo. Accuracy test=0.9711. Artefactos en 'artifacts/'.
```

**Archivos generados:**
- `artifacts/model.pth` - Pesos PyTorch
- `artifacts/model_ts.pt` - **TorchScript (PARA KERNEL)** ‚≠ê
- `artifacts/training_summary.json` - Resumen del entrenamiento

### 4. Evaluar el Modelo

```bash
python evaluate.py
```

**Salida esperada:**
```
Accuracy test: 0.9711
Matriz de confusi√≥n (filas=verdadero, columnas=predicho):
[[55  0  2]
 [ 0 58  0]
 [ 1  2 55]]
```

**Archivo generado:**
- `artifacts/eval_summary.json` - M√©tricas de evaluaci√≥n

---

## üîß Integraci√≥n en el Kernel Linux

### Contexto: ¬øQu√© necesita hacer tu compa√±ero?

El objetivo final es que el modelo se ejecute dentro del kernel Linux para clasificar patrones de I/O en tiempo real y ajustar el readahead din√°micamente.

### Archivos para Entregar

1. **`artifacts/model_ts.pt`** (14.8 KB) ‚≠ê **PRINCIPAL**
   - Modelo en formato TorchScript
   - Formato compatible con C/C++ y KML
   - Se carga directamente en el kernel

2. **`artifacts/scaler.pkl`** (719 bytes) ‚≠ê **CR√çTICO**
   - Contiene los par√°metros de normalizaci√≥n (medias y desviaciones est√°ndar)
   - **NO se carga directamente**, pero sus par√°metros deben implementarse en C
   - Las caracter√≠sticas DEBEN normalizarse antes de cada inferencia

3. **`artifacts/metadata.json`**
   - Mapeo de clases: `{0: "sequential", 1: "random", 2: "mixed"}`
   - Dimensiones: 5 caracter√≠sticas de entrada, 3 clases de salida
   - Referencia para implementaci√≥n

### Proceso de Integraci√≥n (Responsabilidad del compa√±ero)

#### Paso 1: Cargar el Modelo TorchScript
- Usar la biblioteca de KML o wrapper de TorchScript para C
- Cargar `model_ts.pt` en memoria del kernel
- Inicializar el modelo para inferencia

#### Paso 2: Implementar Normalizaci√≥n en C
- Extraer par√°metros del `scaler.pkl` (medias y desviaciones est√°ndar)
- Implementar normalizaci√≥n en C:
  ```c
  normalized_feature[i] = (feature[i] - mean[i]) / std[i]
  ```
- Aplicar a las 5 caracter√≠sticas antes de cada inferencia

#### Paso 3: Extraer Caracter√≠sticas en Tiempo Real
- Interceptar operaciones de I/O en el kernel
- Calcular las 5 caracter√≠sticas por ventana deslizante:
  1. Distancia promedio entre offsets
  2. Variabilidad (jump ratio)
  3. Tama√±o promedio de I/O
  4. Ratio secuencial
  5. IOPS
- Normalizar usando los par√°metros del scaler

#### Paso 4: Ejecutar Inferencia
- Pasar las 5 caracter√≠sticas normalizadas al modelo
- Obtener los 3 logits (scores) de salida
- Seleccionar la clase con mayor score

#### Paso 5: Mapear a Readahead
- Mapear clase predicha a valor de readahead:
  - `0 (sequential)` ‚Üí Readahead alto (ej: 128 KB)
  - `1 (random)` ‚Üí Readahead bajo (ej: 4 KB)
  - `2 (mixed)` ‚Üí Readahead intermedio (ej: 32 KB)
- Ajustar el readahead del sistema de archivos

### Consideraciones T√©cnicas para el Kernel

1. **Memoria limitada**: El modelo es ligero (~15 KB) para no consumir mucha memoria del kernel
2. **Latencia baja**: La inferencia debe ser r√°pida (microsegundos) para no afectar el rendimiento
3. **Normalizaci√≥n obligatoria**: Las caracter√≠sticas DEBEN normalizarse igual que en entrenamiento
4. **Ventana deslizante**: Las caracter√≠sticas se calculan sobre ventanas de operaciones de I/O
5. **Determinismo**: El modelo es determin√≠stico (sin operaciones aleatorias) para comportamiento predecible

### Formato de Entrada para el Modelo

**Input**: Array de 5 valores float32 normalizados
```c
float features[5] = {
    normalized_avg_distance,
    normalized_variability,
    normalized_avg_io_size,
    normalized_seq_ratio,
    normalized_iops
};
```

**Output**: Array de 3 logits (scores)
```c
float logits[3] = {
    score_sequential,  // Clase 0
    score_random,      // Clase 1
    score_mixed        // Clase 2
};
// Clase predicha = √≠ndice del m√°ximo valor
```

---

## üìä Resultados del Modelo

- **Accuracy en test**: 97.11%
- **Distribuci√≥n de clases**: Balanceada (288 muestras por clase)
- **Tama√±o del modelo**: ~15 KB (TorchScript)
- **Tiempo de inferencia**: Microsegundos (optimizado para kernel)

### Matriz de Confusi√≥n
```
                Predicho
              Seq  Rand  Mix
Real Seq       55    0    2
Real Rand       0   58    0
Real Mixed      1    2   55
```

- **Sequential**: 96.5% correctos
- **Random**: 100% correctos
- **Mixed**: 94.8% correctos

---

## üêõ Soluci√≥n de Problemas

### Error: "No se encontraron trazas en 'data/raw'"
- **Soluci√≥n**: Aseg√∫rate de tener `consolidated_dataset.csv` en el directorio ra√≠z

### Error: "No module named 'torch'"
- **Soluci√≥n**: Instala las dependencias: `pip install -r requirements.txt`

### Warning: "exportaci√≥n ONNX fall√≥"
- **No es cr√≠tico**: TorchScript es el formato principal. ONNX es opcional.

### El modelo tiene baja accuracy
- Verifica que el dataset est√© balanceado
- Revisa que las caracter√≠sticas se est√©n calculando correctamente
- Considera ajustar hiperpar√°metros en `train.py`

---

## üìù Notas Importantes

1. **Normalizaci√≥n es CR√çTICA**: El modelo fue entrenado con datos normalizados. Sin normalizaci√≥n, las predicciones ser√°n incorrectas.

2. **Orden de caracter√≠sticas**: Las 5 caracter√≠sticas deben pasarse en el mismo orden:
   - [0] Distancia promedio
   - [1] Variabilidad
   - [2] Tama√±o promedio I/O
   - [3] Ratio secuencial
   - [4] IOPS

3. **Ventana deslizante**: Las caracter√≠sticas se calculan sobre ventanas de operaciones de I/O. El tama√±o de ventana y overlap deben ser consistentes.

4. **TorchScript es el formato principal**: Aunque se exporta ONNX, TorchScript (`model_ts.pt`) es el formato recomendado para integraci√≥n en kernel.

---

## üìö Referencias

- **KML (Kernel Machine Learning)**: Framework para ejecutar modelos ML en el kernel Linux
- **TorchScript**: Formato de PyTorch para exportar modelos a C++
- **StandardScaler**: Normalizaci√≥n z-score: `(x - mean) / std`

---

**√öltima actualizaci√≥n**: Noviembre 2025  
**Estado**: Modelo entrenado y listo para integraci√≥n en kernel ‚úÖ
