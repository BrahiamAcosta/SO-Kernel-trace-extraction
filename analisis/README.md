# AnÃ¡lisis de Resultados FIO - Experimentos de Rendimiento I/O

Este directorio contiene el anÃ¡lisis completo de los experimentos de rendimiento I/O realizados con la herramienta FIO (Flexible I/O Tester).

## ğŸ“‹ Contenido

- **`process_results.py`**: Script para procesar los archivos JSON de resultados y generar datasets estructurados
- **`generate_plots.py`**: Script para generar visualizaciones completas del anÃ¡lisis
- **`generate_report.py`**: Script para generar el reporte de hallazgos en formato Markdown
- **`run_analysis.py`**: Script principal que ejecuta todo el pipeline de anÃ¡lisis
- **`REPORTE_HALLAZGOS.md`**: Reporte detallado con hallazgos y conclusiones (generado)
- GrÃ¡ficas PNG (generadas tras ejecutar el anÃ¡lisis)

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

AsegÃºrate de tener instaladas las siguientes librerÃ­as de Python:

```powershell
pip install pandas numpy matplotlib seaborn
```

O instala todas las dependencias desde el archivo de requisitos del proyecto:

```powershell
pip install -r ../requirements.txt
```

### EjecuciÃ³n del AnÃ¡lisis Completo

Para ejecutar todo el pipeline de anÃ¡lisis de una vez:

```powershell
cd analisis
python run_analysis.py
```

Este comando ejecutarÃ¡:

1. Procesamiento de todos los archivos JSON de resultados
2. GeneraciÃ³n de estadÃ­sticas agregadas
3. CreaciÃ³n de todas las grÃ¡ficas
4. GeneraciÃ³n del reporte de hallazgos

## ğŸ“Š EjecuciÃ³n MÃ³dulo por MÃ³dulo

Si prefieres ejecutar cada componente por separado:

### 1. Procesar Resultados

```powershell
python process_results.py
```

**Salidas generadas:**

- `processed_results.csv`: Dataset completo con todos los experimentos procesados
- `statistics_summary.csv`: EstadÃ­sticas agregadas por configuraciÃ³n

### 2. Generar GrÃ¡ficas

```powershell
python generate_plots.py
```

**GrÃ¡ficas generadas:**

- `iops_comparison.png`: ComparaciÃ³n de IOPS por tipo de acceso y tamaÃ±o
- `bandwidth_comparison.png`: AnÃ¡lisis de ancho de banda
- `latency_analysis.png`: AnÃ¡lisis detallado de latencia (4 subgrÃ¡ficas)
- `throughput_efficiency.png`: Eficiencia de throughput
- `performance_heatmap.png`: Mapas de calor de rendimiento (4 mÃ©tricas)
- `comparative_radar.png`: GrÃ¡fica radar comparativa de rendimiento normalizado
- `variability_analysis.png`: AnÃ¡lisis de consistencia entre runs (4 subgrÃ¡ficas)
- `percentile_latency.png`: Percentiles de latencia (P50, P95, P99)

### 3. Generar Reporte

```powershell
python generate_report.py
```

**Salida generada:**

- `REPORTE_HALLAZGOS.md`: Reporte completo en formato Markdown con:
  - Resumen ejecutivo
  - MÃ©tricas principales
  - AnÃ¡lisis por tipo de acceso
  - AnÃ¡lisis de escalabilidad
  - AnÃ¡lisis de latencia
  - AnÃ¡lisis de variabilidad
  - Hallazgos clave
  - Recomendaciones
  - Conclusiones

## ğŸ“ˆ Estructura de Datos

### Datos de Entrada

Los scripts procesan los resultados ubicados en:

```
../experiments/results_baseline/
â”œâ”€â”€ seq/
â”‚   â”œâ”€â”€ 100M/
â”‚   â”‚   â”œâ”€â”€ result_100M_run1.json
â”‚   â”‚   â”œâ”€â”€ result_100M_run2.json
â”‚   â”‚   â””â”€â”€ result_100M_run3.json
â”‚   â”œâ”€â”€ 500M/
â”‚   â””â”€â”€ 1G/
â”œâ”€â”€ rand/
â”‚   â”œâ”€â”€ 100M/
â”‚   â”œâ”€â”€ 500M/
â”‚   â””â”€â”€ 1G/
â””â”€â”€ mix/
    â”œâ”€â”€ 100M/
    â”œâ”€â”€ 500M/
    â””â”€â”€ 1G/
```

### ConfiguraciÃ³n de Experimentos

- **Patrones de acceso**: Secuencial (seq), Aleatorio (rand), Mixto (mix)
- **TamaÃ±os de archivo**: 100M, 500M, 1G
- **Repeticiones**: 3 runs por configuraciÃ³n
- **Total de experimentos**: 27 ejecuciones (3 Ã— 3 Ã— 3)

### MÃ©tricas Analizadas

#### Principales

- **IOPS** (I/O Operations Per Second): Operaciones de entrada/salida por segundo
- **Ancho de Banda** (MB/s): Throughput en megabytes por segundo
- **Latencia** (Î¼s): Tiempo de respuesta en microsegundos

#### MÃ©tricas Detalladas

- Latencia media, mÃ­nima, mÃ¡xima y desviaciÃ³n estÃ¡ndar
- Percentiles de latencia (P50, P95, P99)
- Total de datos procesados
- Throughput efectivo
- Coeficiente de variaciÃ³n

## ğŸ” InterpretaciÃ³n de Resultados

### IOPS (Input/Output Operations Per Second)

- **Mayor es mejor**
- Indica cuÃ¡ntas operaciones de I/O puede procesar el sistema por segundo
- CrÃ­tico para aplicaciones con muchas operaciones pequeÃ±as

### Ancho de Banda (Bandwidth)

- **Mayor es mejor**
- Medido en MB/s
- Indica la cantidad de datos que pueden transferirse por unidad de tiempo
- Importante para operaciones con archivos grandes

### Latencia

- **Menor es mejor**
- Medida en microsegundos (Î¼s)
- Tiempo que tarda en completarse una operaciÃ³n de I/O
- Los percentiles altos (P95, P99) son crÃ­ticos para detectar outliers

### Coeficiente de VariaciÃ³n (CV)

- Mide la consistencia de los resultados entre ejecuciones
- **CV < 5%**: Excelente consistencia
- **CV 5-10%**: Buena consistencia
- **CV 10-15%**: Consistencia moderada
- **CV > 15%**: Alta variabilidad

## ğŸ“¦ Archivos Generados

DespuÃ©s de ejecutar el anÃ¡lisis completo, encontrarÃ¡s:

```
analisis/
â”œâ”€â”€ process_results.py
â”œâ”€â”€ generate_plots.py
â”œâ”€â”€ generate_report.py
â”œâ”€â”€ run_analysis.py
â”œâ”€â”€ README.md
â”œâ”€â”€ processed_results.csv           # Dataset procesado
â”œâ”€â”€ statistics_summary.csv          # EstadÃ­sticas agregadas
â”œâ”€â”€ REPORTE_HALLAZGOS.md           # Reporte de hallazgos
â”œâ”€â”€ iops_comparison.png
â”œâ”€â”€ bandwidth_comparison.png
â”œâ”€â”€ latency_analysis.png
â”œâ”€â”€ throughput_efficiency.png
â”œâ”€â”€ performance_heatmap.png
â”œâ”€â”€ comparative_radar.png
â”œâ”€â”€ variability_analysis.png
â””â”€â”€ percentile_latency.png
```

## ğŸ› ï¸ PersonalizaciÃ³n

### Modificar Rutas

Si tus resultados estÃ¡n en una ubicaciÃ³n diferente, modifica la variable `results_path` en cada script:

```python
results_path = Path('ruta/a/tus/resultados')
```

### Agregar Nuevas MÃ©tricas

1. Edita `process_results.py` para extraer mÃ©tricas adicionales del JSON
2. Actualiza `generate_plots.py` para visualizar las nuevas mÃ©tricas
3. Modifica `generate_report.py` para incluirlas en el reporte

### Cambiar Estilo de GrÃ¡ficas

En `generate_plots.py`, ajusta los parÃ¡metros de estilo:

```python
plt.style.use('seaborn-v0_8-darkgrid')  # Cambiar estilo
sns.set_palette("husl")                  # Cambiar paleta de colores
plt.rcParams['figure.figsize'] = (12, 8) # Ajustar tamaÃ±o
```

## ğŸ“Š Visualizaciones Disponibles

### 1. IOPS Comparison

- Barras agrupadas y box plots
- Compara IOPS entre patrones de acceso y tamaÃ±os

### 2. Bandwidth Comparison

- Barras y grÃ¡ficas de lÃ­nea
- Muestra tendencias de ancho de banda

### 3. Latency Analysis

- 4 subgrÃ¡ficas con anÃ¡lisis completo
- Incluye distribuciÃ³n, variabilidad y rangos

### 4. Throughput Efficiency

- Throughput efectivo y datos procesados
- EvalÃºa eficiencia del sistema

### 5. Performance Heatmap

- 4 mapas de calor
- VisualizaciÃ³n rÃ¡pida de patrones de rendimiento

### 6. Comparative Radar

- GrÃ¡fica tipo radar
- Compara rendimiento normalizado entre patrones

### 7. Variability Analysis

- 4 subgrÃ¡ficas sobre consistencia
- EvalÃºa variabilidad entre runs

### 8. Percentile Latency

- Percentiles P50, P95 y P99
- Identifica latencias extremas

## ğŸ› SoluciÃ³n de Problemas

### Error: "No module named 'pandas'"

```powershell
pip install pandas numpy matplotlib seaborn
```

### Error: "File not found"

Verifica que los resultados estÃ©n en la ruta correcta:

```
../experiments/results_baseline/
```

### GrÃ¡ficas no se generan

AsegÃºrate de haber ejecutado primero `process_results.py` o `run_analysis.py`

### Warnings sobre seaborn

Si ves warnings sobre estilos de seaborn, es normal. Las grÃ¡ficas se generarÃ¡n correctamente.

## ğŸ“ Notas Adicionales

- Todos los scripts estÃ¡n diseÃ±ados para ejecutarse de forma independiente o conjunta
- Los resultados son reproducibles gracias al procesamiento determinÃ­stico
- Las grÃ¡ficas se generan en alta resoluciÃ³n (300 DPI) para publicaciones
- El reporte estÃ¡ en formato Markdown, fÃ¡cil de convertir a PDF o HTML

## ğŸ“ Contacto y Soporte

Para preguntas o problemas relacionados con el anÃ¡lisis:

- Revisa el cÃ³digo fuente de los scripts (estÃ¡n bien comentados)
- Consulta el reporte de hallazgos generado
- Verifica que todos los prerequisitos estÃ©n instalados

## ğŸ”„ ActualizaciÃ³n de AnÃ¡lisis

Para actualizar el anÃ¡lisis con nuevos resultados:

1. AsegÃºrate de que los nuevos archivos JSON estÃ©n en la estructura correcta
2. Ejecuta nuevamente:
   ```powershell
   python run_analysis.py
   ```
3. Los archivos existentes serÃ¡n sobrescritos con los nuevos resultados

## ğŸ“„ Licencia

Este cÃ³digo de anÃ¡lisis es parte del proyecto SO-Kernel-trace-extraction.

---

**Ãšltima actualizaciÃ³n:** Diciembre 2025
