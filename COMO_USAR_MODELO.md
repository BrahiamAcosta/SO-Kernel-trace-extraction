# C√≥mo Usar el Modelo para Hacer Predicciones

Esta gu√≠a explica c√≥mo usar el modelo entrenado para predecir patrones de I/O a partir de datos nuevos.

---

## üìã Resumen R√°pido

Para hacer una predicci√≥n necesitas:

1. **Calcular las 5 caracter√≠sticas** a partir de una ventana de operaciones de I/O
2. **Normalizar** las caracter√≠sticas usando el scaler
3. **Pasar al modelo** y obtener la predicci√≥n

---

## üî¢ Las 5 Caracter√≠sticas que Necesitas

El modelo espera exactamente estas 5 caracter√≠sticas en este orden:

### 1. Distancia promedio entre offsets (en bytes)
- **C√≥mo calcular**: Toma los offsets de las operaciones de I/O en una ventana, calcula las distancias entre consecutivos, y promedia el valor absoluto
- **Ejemplo secuencial**: ~5,120 bytes (10 sectores √ó 512 bytes)
- **Ejemplo aleatorio**: ~25,600,000 bytes (50,000 sectores √ó 512 bytes)

### 2. Variabilidad (jump ratio) (0.0 - 1.0)
- **C√≥mo calcular**: Porcentaje de saltos grandes (>1MB) entre accesos consecutivos
- **Ejemplo secuencial**: 0.05 (5% de saltos grandes)
- **Ejemplo aleatorio**: 0.90 (90% de saltos grandes)

### 3. Tama√±o promedio de I/O (en bytes)
- **C√≥mo calcular**: Promedio del tama√±o de cada operaci√≥n de I/O en la ventana
- **Alternativa**: Si no tienes el tama√±o directo, calcula: `(bandwidth_kbps √ó 1024) / iops`
- **Ejemplo secuencial**: ~1,280,000 bytes (1.28 MB por operaci√≥n)
- **Ejemplo aleatorio**: ~5,120 bytes (4 KB por operaci√≥n)

### 4. Ratio secuencial (0.0 - 1.0)
- **C√≥mo calcular**: `1 - jump_ratio` (inverso de la variabilidad)
- **Ejemplo secuencial**: 0.95 (95% de accesos secuenciales)
- **Ejemplo aleatorio**: 0.10 (10% de accesos secuenciales)

### 5. IOPS (operaciones por segundo)
- **C√≥mo calcular**: N√∫mero de operaciones de I/O por segundo en la ventana
- **Ejemplo secuencial**: 400 ops/s
- **Ejemplo aleatorio**: 3,000 ops/s

---

## üíª C√≥digo de Ejemplo

### Opci√≥n 1: Usar el script `predict.py`

```bash
python predict.py
```

Este script muestra ejemplos completos de c√≥mo hacer predicciones.

### Opci√≥n 2: Usar en tu propio c√≥digo

```python
import joblib
import numpy as np
import torch
from neuronal_red import IOPatternClassifier

# 1. Cargar modelo y scaler
scaler = joblib.load("artifacts/scaler.pkl")
model = IOPatternClassifier(input_size=5, hidden_size=32, num_classes=3)
model.load_state_dict(torch.load("artifacts/model.pth", map_location="cpu"))
model.eval()

# 2. Preparar tus caracter√≠sticas (ejemplo: patr√≥n secuencial)
features = np.array([
    5120.0,      # [0] Distancia promedio: 5120 bytes
    0.05,        # [1] Variabilidad: 0.05
    1280000.0,   # [2] Tama√±o promedio I/O: 1.28 MB
    0.95,        # [3] Ratio secuencial: 0.95
    400.0        # [4] IOPS: 400
], dtype=np.float32)

# 3. CR√çTICO: Normalizar las caracter√≠sticas
features_normalized = scaler.transform(features.reshape(1, -1))

# 4. Convertir a tensor y hacer predicci√≥n
features_tensor = torch.tensor(features_normalized, dtype=torch.float32)

with torch.no_grad():
    logits = model(features_tensor)
    probabilities = torch.softmax(logits, dim=1)
    predicted_class = torch.argmax(logits, dim=1).item()

# 5. Interpretar resultado
class_map = {0: "sequential", 1: "random", 2: "mixed"}
predicted_label = class_map[predicted_class]
confidence = probabilities[0][predicted_class].item()

print(f"Predicci√≥n: {predicted_label} (confianza: {confidence*100:.2f}%)")
```

---

## üìä Ejemplos de Valores T√≠picos

### Patr√≥n Secuencial
```python
features = [
    5120.0,      # Distancia peque√±a
    0.05,        # Bajo jump ratio
    1280000.0,   # Requests grandes
    0.95,        # Alto ratio secuencial
    400.0        # Bajo IOPS
]
# Resultado esperado: "sequential" con alta confianza
```

### Patr√≥n Aleatorio
```python
features = [
    25600000.0,  # Distancia grande
    0.90,        # Alto jump ratio
    5120.0,      # Requests peque√±os
    0.10,        # Bajo ratio secuencial
    3000.0       # Alto IOPS
]
# Resultado esperado: "random" con alta confianza
```

### Patr√≥n Mixto
```python
features = [
    1024000.0,   # Distancia intermedia
    0.50,        # Jump ratio intermedio
    102400.0,    # Requests medianos
    0.50,        # Ratio secuencial intermedio
    1500.0       # IOPS intermedio
]
# Resultado esperado: "mixed" con confianza moderada
```

---

## ‚ö†Ô∏è Puntos Cr√≠ticos

### 1. Normalizaci√≥n es OBLIGATORIA
**‚ùå INCORRECTO:**
```python
features = np.array([5120.0, 0.05, 1280000.0, 0.95, 400.0])
prediction = model(torch.tensor(features))  # ‚Üê ERROR: Sin normalizar
```

**‚úÖ CORRECTO:**
```python
features = np.array([5120.0, 0.05, 1280000.0, 0.95, 400.0])
features_normalized = scaler.transform(features.reshape(1, -1))  # ‚Üê Normalizar primero
prediction = model(torch.tensor(features_normalized))
```

### 2. Orden de Caracter√≠sticas
Las caracter√≠sticas **DEBEN** estar en este orden exacto:
- [0] Distancia promedio
- [1] Variabilidad
- [2] Tama√±o promedio I/O
- [3] Ratio secuencial
- [4] IOPS

### 3. Tipo de Datos
- Usa `float32` (no `float64` o `int`)
- El array debe tener shape `(5,)` o `(1, 5)`

### 4. Ventana de Datos
- Las caracter√≠sticas deben calcularse sobre una **ventana de operaciones de I/O**
- Recomendado: √∫ltimas 32 operaciones (o ventana de 2.5 segundos)
- Debe ser consistente con c√≥mo se entren√≥ el modelo

---

## üîç Interpretaci√≥n de Resultados

El modelo retorna:
- **Clase predicha**: 0 (sequential), 1 (random), o 2 (mixed)
- **Probabilidades**: Distribuci√≥n de probabilidad sobre las 3 clases
- **Confianza**: Probabilidad de la clase predicha

**Ejemplo de salida:**
```
Predicci√≥n: sequential
Confianza: 95.23%
Probabilidades:
  sequential: 95.23%
  random:     2.10%
  mixed:      2.67%
```

**Interpretaci√≥n:**
- Si la confianza es > 80%: Predicci√≥n muy confiable
- Si la confianza es 50-80%: Predicci√≥n moderada (puede ser patr√≥n mixto o transici√≥n)
- Si la confianza es < 50%: Revisar los datos de entrada

---

## üß™ Probar con Datos Reales

Si tienes datos reales de operaciones de I/O:

1. **Agrupa en ventanas**: Toma las √∫ltimas N operaciones (ej: 32)
2. **Calcula las 5 caracter√≠sticas** seg√∫n las f√≥rmulas arriba
3. **Usa el script `predict.py`** o el c√≥digo de ejemplo
4. **Interpreta el resultado**

**Ejemplo con datos reales:**
```python
# Supongamos que tienes una lista de operaciones de I/O
io_operations = [
    {"offset": 0, "size": 131072, "timestamp": 0.0},
    {"offset": 131072, "size": 131072, "timestamp": 0.1},
    {"offset": 262144, "size": 131072, "timestamp": 0.2},
    # ... m√°s operaciones
]

# Calcular caracter√≠sticas
offsets = [op["offset"] for op in io_operations]
distances = [abs(offsets[i+1] - offsets[i]) for i in range(len(offsets)-1)]
avg_distance = np.mean(distances)

# ... calcular las otras 4 caracter√≠sticas ...

# Hacer predicci√≥n
features = np.array([avg_distance, jump_ratio, avg_size, seq_ratio, iops])
result = predict(model, scaler, features, metadata)
```

---

## üìù Resumen

**Para hacer una predicci√≥n:**

1. ‚úÖ Calcula las 5 caracter√≠sticas de una ventana de I/O
2. ‚úÖ Crea un array numpy: `np.array([f1, f2, f3, f4, f5], dtype=np.float32)`
3. ‚úÖ Normaliza: `scaler.transform(features.reshape(1, -1))`
4. ‚úÖ Pasa al modelo: `model(torch.tensor(features_normalized))`
5. ‚úÖ Interpreta: `torch.argmax(logits)` para la clase, `torch.softmax(logits)` para probabilidades

**¬°Listo!** üéâ

